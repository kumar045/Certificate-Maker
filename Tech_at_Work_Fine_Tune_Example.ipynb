{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumar045/Certificate-Maker/blob/main/Tech_at_Work_Fine_Tune_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3xI_himM5NW",
        "outputId": "0a7ce0fc-b5eb-4f4e-aefa-3869f1b0c69e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.7 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.31.0-py3-none-any.whl (17.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from gradio)\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio) (3.8.4)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.95.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.4 (from gradio)\n",
            "  Downloading gradio_client-0.2.5-py3-none-any.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.1/288.1 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.13.0 (from gradio)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio)\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n",
            "Collecting orjson (from gradio)\n",
            "  Downloading orjson-3.8.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.7)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.14.0)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n",
            "Collecting semantic-version (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio) (2023.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (3.12.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2022.12.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n",
            "  Downloading httpcore-0.17.1-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.9/70.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio) (1.26.15)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=3c6f57517c8f27af80d8c8fab4fed153122fdb8d6cafe74d885d0037788e0c5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, semantic-version, python-multipart, orjson, h11, aiofiles, uvicorn, starlette, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.1.0 fastapi-0.95.2 ffmpy-0.3.0 gradio-3.31.0 gradio-client-0.2.5 h11-0.14.0 httpcore-0.17.1 httpx-0.24.1 huggingface-hub-0.14.1 linkify-it-py-2.0.2 mdit-py-plugins-0.3.3 orjson-3.8.12 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "! pip install openai\n",
        "! pip install pandas\n",
        "! pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "IBVpcuFmNhUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"sk-YOUR KEY\""
      ],
      "metadata": {
        "id": "lqEXxl_TNm2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/contents/DRIVE LOCATION/file.csv'\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "_DjkzI11Nvco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/contents/DRIVE LOCATION/file_pandas.csv', index=False)"
      ],
      "metadata": {
        "id": "nWaRaQcbPPTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!openai tools fine_tunes.prepare_data -f /content/drive/MyDrive/Airline-Tweets/tweets_pandas.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4RGoWQtPsAO",
        "outputId": "518fd619-ce3c-4a52-efe5-97430387601a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Based on your file extension, your file is formatted as a CSV file\n",
            "- Your file contains 1007 prompt-completion pairs\n",
            "- The input file should contain exactly two columns/keys per row. Additional columns/keys present are: ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13']\n",
            "  WARNING: Some of the additional columns/keys contain `Unnamed: 2` in their name. These will be ignored, and the column/key `Unnamed: 2` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
            "  WARNING: Some of the additional columns/keys contain `Unnamed: 3` in their name. These will be ignored, and the column/key `Unnamed: 3` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
            "  WARNING: Some of the additional columns/keys contain `Unnamed: 4` in their name. These will be ignored, and the column/key `Unnamed: 4` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
            "  WARNING: Some of the additional columns/keys contain `Unnamed: 5` in their name. These will be ignored, and the column/key `Unnamed: 5` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
            "  WARNING: Some of the additional columns/keys contain `Unnamed: 6` in their name. These will be ignored, and the column/key `Unnamed: 6` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
            "  WARNING: Some of the additional columns/keys contain `Unnamed: 7` in their name. These will be ignored, and the column/key `Unnamed: 7` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
            "  WARNING: Some of the additional columns/keys contain `Unnamed: 8` in their name. These will be ignored, and the column/key `Unnamed: 8` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
            "  WARNING: Some of the additional columns/keys contain `Unnamed: 9` in their name. These will be ignored, and the column/key `Unnamed: 9` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
            "  WARNING: Some of the additional columns/keys contain `Unnamed: 10` in their name. These will be ignored, and the column/key `Unnamed: 10` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
            "  WARNING: Some of the additional columns/keys contain `Unnamed: 11` in their name. These will be ignored, and the column/key `Unnamed: 11` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
            "  WARNING: Some of the additional columns/keys contain `Unnamed: 12` in their name. These will be ignored, and the column/key `Unnamed: 12` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
            "  WARNING: Some of the additional columns/keys contain `Unnamed: 13` in their name. These will be ignored, and the column/key `Unnamed: 13` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
            "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
            "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
            "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
            "- There are 2 duplicated prompt-completion sets. These are rows: [327, 511]\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Necessary] Your format `CSV` will be converted to `JSONL`\n",
            "- [Necessary] Remove additional columns/keys: ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13']\n",
            "- [Recommended] Remove 2 duplicate rows [Y/n]: Y\n",
            "- [Recommended] Add a suffix separator `\\n\\n###\\n\\n` to all prompts [Y/n]: Y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
            "- [Recommended] Would you like to split into training and validation set? [Y/n]: n\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified file to `/content/drive/MyDrive/Airline-Tweets/tweets_pandas_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"/content/drive/MyDrive/Airline-Tweets/tweets_pandas_prepared.jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt.\n",
            "Once your model starts training, it'll approximately take 26.45 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_training_file(file_path):\n",
        "  file = openai.File.create(\n",
        "      file=open(file_path, \"rb\"),\n",
        "      purpose=\"fine-tune\"\n",
        "  )\n",
        "  return file\n",
        "\n",
        "\n",
        "training_file = create_training_file(\"/contents/DRIVE LOCATION/file_prepared.jsonl\")\n",
        "print(training_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OCeT3b8S4nz",
        "outputId": "d7c996e3-de8e-4733-b3c8-0ec28d24bfef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"bytes\": 154537,\n",
            "  \"created_at\": 1684538295,\n",
            "  \"filename\": \"file\",\n",
            "  \"id\": \"file-xjSgFivxFlmkwCsWYv2vtWsO\",\n",
            "  \"object\": \"file\",\n",
            "  \"purpose\": \"fine-tune\",\n",
            "  \"status\": \"uploaded\",\n",
            "  \"status_details\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_file['id']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dIfv1AZ-T3Ul",
        "outputId": "97478176-a484-441a-89cb-e9b8043bf521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'file-xjSgFivxFlmkwCsWYv2vtWsO'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_model = openai.FineTune.create(training_file=training_file['id'],\n",
        "model ='ada',\n",
        "n_epochs=4)\n",
        "print(fine_tuned_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce4S3rX9UCT8",
        "outputId": "8f910866-38d5-4eed-ee4a-273aa7839130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"created_at\": 1684538664,\n",
            "  \"events\": [\n",
            "    {\n",
            "      \"created_at\": 1684538664,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Created fine-tune: ft-hKKejuxmB0FazBYlRvJd5Ho6\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    }\n",
            "  ],\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"hyperparams\": {\n",
            "    \"batch_size\": null,\n",
            "    \"learning_rate_multiplier\": null,\n",
            "    \"n_epochs\": 4,\n",
            "    \"prompt_loss_weight\": 0.01\n",
            "  },\n",
            "  \"id\": \"ft-hKKejuxmB0FazBYlRvJd5Ho6\",\n",
            "  \"model\": \"ada\",\n",
            "  \"object\": \"fine-tune\",\n",
            "  \"organization_id\": \"org-pWoX9YzaETZVCbyWbebFq8ld\",\n",
            "  \"result_files\": [],\n",
            "  \"status\": \"pending\",\n",
            "  \"training_files\": [\n",
            "    {\n",
            "      \"bytes\": 154537,\n",
            "      \"created_at\": 1684538295,\n",
            "      \"filename\": \"file\",\n",
            "      \"id\": \"file-xjSgFivxFlmkwCsWYv2vtWsO\",\n",
            "      \"object\": \"file\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ],\n",
            "  \"updated_at\": 1684538664,\n",
            "  \"validation_files\": []\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTune.list_events(id=\"ft-MODEL ABOVE\") ['data']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK9Xv5jRV7tQ",
        "outputId": "a81ae27f-7185-4016-de62-cf005e2b98ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<OpenAIObject fine-tune-event at 0x7f95dfb54c70> JSON: {\n",
              "   \"created_at\": 1684538664,\n",
              "   \"level\": \"info\",\n",
              "   \"message\": \"Created fine-tune: ft-hKKejuxmB0FazBYlRvJd5Ho6\",\n",
              "   \"object\": \"fine-tune-event\"\n",
              " },\n",
              " <OpenAIObject fine-tune-event at 0x7f95dfb56e80> JSON: {\n",
              "   \"created_at\": 1684538809,\n",
              "   \"level\": \"info\",\n",
              "   \"message\": \"Fine-tune costs $0.05\",\n",
              "   \"object\": \"fine-tune-event\"\n",
              " },\n",
              " <OpenAIObject fine-tune-event at 0x7f95dfb57880> JSON: {\n",
              "   \"created_at\": 1684538809,\n",
              "   \"level\": \"info\",\n",
              "   \"message\": \"Fine-tune enqueued. Queue number: 0\",\n",
              "   \"object\": \"fine-tune-event\"\n",
              " },\n",
              " <OpenAIObject fine-tune-event at 0x7f95df9f2980> JSON: {\n",
              "   \"created_at\": 1684538812,\n",
              "   \"level\": \"info\",\n",
              "   \"message\": \"Fine-tune started\",\n",
              "   \"object\": \"fine-tune-event\"\n",
              " },\n",
              " <OpenAIObject fine-tune-event at 0x7f95dfa0cea0> JSON: {\n",
              "   \"created_at\": 1684539017,\n",
              "   \"level\": \"info\",\n",
              "   \"message\": \"Completed epoch 1/4\",\n",
              "   \"object\": \"fine-tune-event\"\n",
              " },\n",
              " <OpenAIObject fine-tune-event at 0x7f95dfa0da80> JSON: {\n",
              "   \"created_at\": 1684539209,\n",
              "   \"level\": \"info\",\n",
              "   \"message\": \"Completed epoch 2/4\",\n",
              "   \"object\": \"fine-tune-event\"\n",
              " },\n",
              " <OpenAIObject fine-tune-event at 0x7f95dfa0c540> JSON: {\n",
              "   \"created_at\": 1684539401,\n",
              "   \"level\": \"info\",\n",
              "   \"message\": \"Completed epoch 3/4\",\n",
              "   \"object\": \"fine-tune-event\"\n",
              " },\n",
              " <OpenAIObject fine-tune-event at 0x7f95dfa0c6d0> JSON: {\n",
              "   \"created_at\": 1684539593,\n",
              "   \"level\": \"info\",\n",
              "   \"message\": \"Completed epoch 4/4\",\n",
              "   \"object\": \"fine-tune-event\"\n",
              " },\n",
              " <OpenAIObject fine-tune-event at 0x7f95dfa0fa60> JSON: {\n",
              "   \"created_at\": 1684539622,\n",
              "   \"level\": \"info\",\n",
              "   \"message\": \"Uploaded model: ada:ft-personal-2023-05-19-23-40-22\",\n",
              "   \"object\": \"fine-tune-event\"\n",
              " },\n",
              " <OpenAIObject fine-tune-event at 0x7f95dfa0f650> JSON: {\n",
              "   \"created_at\": 1684539623,\n",
              "   \"level\": \"info\",\n",
              "   \"message\": \"Uploaded result file: file-VXPjQk71xWEZywPbEadXWIHv\",\n",
              "   \"object\": \"fine-tune-event\"\n",
              " },\n",
              " <OpenAIObject fine-tune-event at 0x7f95dfa0c9a0> JSON: {\n",
              "   \"created_at\": 1684539623,\n",
              "   \"level\": \"info\",\n",
              "   \"message\": \"Fine-tune succeeded\",\n",
              "   \"object\": \"fine-tune-event\"\n",
              " }]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_text = \"TEST TWEET \\n\\n###\\n\\n\"\n",
        "response = openai.Completion.create(\n",
        "    model=\"ada:YOUR MODEL\",\n",
        "    prompt=prompt_text,\n",
        "    max_tokens=5,\n",
        "    temperature=0\n",
        ")\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObH1lUnScFmc",
        "outputId": "c6a5be0f-b010-4b01-8cf2-f0fde08643b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " negative\n",
            " negative\n",
            " negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_completion(user_prompt):\n",
        "    hidden_context = \" \"\n",
        "    prompt = hidden_context + user_prompt\n",
        "    response = openai.Completion.create(\n",
        "        model=\"ada:YOUR MODEL\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=10,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "iface = gr.Interface(fn=generate_completion, \n",
        "                     inputs=gr.inputs.Textbox(lines=5, placeholder='Enter a tweet...'), \n",
        "                     outputs='text',\n",
        "                     title=\"Twitter Flight Happiness\",\n",
        "                     description=\"Based on thousands of tweets, determines if the tweet you entered is positive, negative, or nuetral\",\n",
        "                     input_labels=\"Tweet\",\n",
        "                     output_labels=\"Sentiment\")\n",
        "\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "UObAu6zqdcqE",
        "outputId": "8fc1e40c-8297-462a-b885-1cbf72b95f5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:30: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  super().__init__(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:30: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  super().__init__(\n",
            "<ipython-input-62-d90c40c5c2a3>:11: UserWarning: You have unused kwarg parameters in Interface, please remove them: {'input_labels': 'Tweet', 'output_labels': 'Sentiment'}\n",
            "  iface = gr.Interface(fn=generate_completion,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://41bf53283239bd397e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://41bf53283239bd397e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    }
  ]
}